{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVxsvBcI8dUQ"
      },
      "source": [
        "---\n",
        "\n",
        "# Proyecto 1: Hack a Boss\n",
        "## Análisis del Top 25 ETFs\n",
        "\n",
        "Proyecto de análisis del Top 25 de ETFs.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe2VYO2XiTyD"
      },
      "source": [
        "# Instalación e importación de **librerías**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNWwNi4bjsyU",
        "outputId": "f7e885fd-6f68-41a0-ca11-3a93460c8bd2"
      },
      "outputs": [],
      "source": [
        "# Instalar las librerías\n",
        "%pip install matplotlib\n",
        "%pip install seaborn\n",
        "%pip install yfinance\n",
        "%pip install yahooquery\n",
        "%pip install yahoofinancials\n",
        "%pip install nbformat\n",
        "%pip install scipy\n",
        "%pip install plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MlkMIe84ilo-"
      },
      "outputs": [],
      "source": [
        "# Importar las librerías\n",
        "import time\n",
        "import requests\n",
        "import warnings\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import yahooquery as yq\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from bs4 import BeautifulSoup\n",
        "from pprint import pprint\n",
        "from tqdm import tqdm\n",
        "from scipy import stats\n",
        "from alpha_vantage.timeseries import TimeSeries\n",
        "from alpha_vantage.techindicators import TechIndicators\n",
        "from alpha_vantage.fundamentaldata import FundamentalData\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ts = TimeSeries(output_format = 'pandas', indexing_type = 'date')\n",
        "ti = TechIndicators(output_format = 'pandas', indexing_type = 'date')\n",
        "fd = FundamentalData(output_format = 'pandas', indexing_type = 'date')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlJUrQZjA1z9"
      },
      "source": [
        "# Descarga y extracción de datos (API y WebScraping)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxhQ462raPsG"
      },
      "outputs": [],
      "source": [
        "HEADERS = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
        "\n",
        "def seleccion_etf(tipo_etfs:str, num:int) -> list:\n",
        "    # Obtención de los símbolos del Top ETFs de EEUU\n",
        "    s = yq.Screener()\n",
        "    dict_query = s.get_screeners(tipo_etfs, num)\n",
        "    tickers = [symbol['symbol'] for symbol in dict_query[tipo_etfs]['quotes']]\n",
        "    return tickers\n",
        "\n",
        "def corregir_nombres_columnas(df_columns:pd.Index) -> pd.Index:\n",
        "    # Eliminar caracteres especiales\n",
        "    df_columns = df_columns.str.replace('[^\\w\\s]', '', regex=True)\n",
        "    # Sustituir espacios por _\n",
        "    df_columns = df_columns.str.replace(' ', '_')\n",
        "    # Retornar el DF\n",
        "    return(df_columns)\n",
        "\n",
        "def convertir_a_largo(df):\n",
        "    # Resetear índice\n",
        "    df_reset = df.reset_index()\n",
        "    # Convertir el dataframe a formato largo\n",
        "    df_melted = df_reset.melt(id_vars='Date', var_name=['Attribute', 'Ticker'], value_name='Value')\n",
        "    # Una columna para cada cosa\n",
        "    df_melted['Attribute'] = df_melted['Attribute'].astype(str)\n",
        "    df_pivoted = df_melted.pivot_table(index=['Date', 'Ticker'], columns='Attribute', values='Value').reset_index()\n",
        "    # Ponerlo todo bien y en orden\n",
        "    df_pivoted.columns.name = None\n",
        "    df_pivoted = df_pivoted[['Date', 'Ticker', 'Adj Close', 'Volume']]\n",
        "    df_pivoted = df_pivoted.rename(\n",
        "        columns={\n",
        "            'Date':'Fecha',\n",
        "            'Ticker':'Ticker',\n",
        "            'Adj Close':'Precio',\n",
        "            'Volume':'Volumen'\n",
        "            }\n",
        "        )\n",
        "    # Retornar dataframe\n",
        "    return df_pivoted\n",
        "\n",
        "def convertir_a_ancho(df_largo):\n",
        "    # Convertir el DataFrame a formato largo\n",
        "    df_wide = df_largo.pivot_table(index='Fecha', columns='Ticker', values=['Precio', 'Volumen'], aggfunc='first')\n",
        "    # Retornar el DataFrame en formato ancho\n",
        "    return df_wide\n",
        "\n",
        "def down_price_vol(tickers:list) -> pd.DataFrame:\n",
        "    # Descarga de las cotizaciones\n",
        "    df = yf.download(tickers, period='max')\n",
        "    # Obtener los nombres de las columnas para 'Adj Close' y 'Volume'\n",
        "    adj_close_cols = [('Adj Close', ticker) for ticker in tickers]\n",
        "    volume_cols = [('Volume', ticker) for ticker in tickers]\n",
        "\n",
        "    # Seleccionar las columnas de interés\n",
        "    df = df[adj_close_cols + volume_cols]\n",
        "    # Eliminar valores nulos y cambiar los precios por incrementos porcentuales\n",
        "    df = df.dropna().pct_change(1).dropna()\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "    # Retornar DataFrame\n",
        "    return(df)\n",
        "\n",
        "def web_scraping_sectors(tickers:list) -> pd.DataFrame:\n",
        "    url_base = \"https://es.finance.yahoo.com/quote/\"\n",
        "    lista_sectores = [\n",
        "        \"Materiales básicos\", \"Acciones cíclicas\", \"Servicios financieros\",\n",
        "        \"Propiedades inmobiliarias\", \"Acciones defensivas\", \"Atención sanitaria\",\n",
        "        \"Utilidades\", \"Servicios de comunicación\", \"Energía\", \"Industriales\",\n",
        "        \"Tecnología\"\n",
        "    ]\n",
        "    dict_sectores = {}\n",
        "    for etf in tqdm(tickers):\n",
        "        url = f'{url_base}{etf}/holdings?p={etf}'\n",
        "        response = requests.get(url, headers = HEADERS)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        sectores_etf = {}\n",
        "        lista_contenedores = soup.findAll('div', class_='Bdbw(1px) Bdbc($seperatorColor) Bdbs(s) H(25px) Pt(10px)')\n",
        "        for item in lista_contenedores:\n",
        "            sector = item.find('span', class_='Mend(5px) Whs(nw)').text\n",
        "            if sector in lista_sectores:\n",
        "                valor = item.find('span', class_='W(20%) D(b) Fl(start) Ta(e)').text\n",
        "                sectores_etf[sector] = valor\n",
        "        dict_sectores[etf] = sectores_etf\n",
        "        time.sleep(0.5)\n",
        "    # Convertir diccionario en dataframe\n",
        "    df = pd.DataFrame.from_dict(dict_sectores).T\n",
        "    # Convertir todas las entradas a strings, eliminar el '%' y reemplazar comas por puntos\n",
        "    df = df.map(lambda x: str(x).replace('%', '').replace(',', '.'))\n",
        "    # Convertir las cadenas a números flotantes y dividir por 100 para tener los porcentajes en formato decimal\n",
        "    df = df.map(lambda x: float(x) / 100.0 if x != 'N/A' else 0)\n",
        "    # Quitar los espacios\n",
        "    df.columns = corregir_nombres_columnas(df.columns)\n",
        "    # Resetear índice\n",
        "    df = df.reset_index()\n",
        "    df = df.rename(columns={'index':'Ticker'})\n",
        "    # Retornar DataFrame\n",
        "    return (df)\n",
        "\n",
        "def tabla_net_assets(tickers:list) -> pd.DataFrame:\n",
        "    def convertir_valor(valor):\n",
        "        if 'M' in valor:\n",
        "            return float(valor.replace('M', ''))\n",
        "        elif 'B' in valor:\n",
        "            return float(valor.replace('B', '')) * 1000\n",
        "        else:\n",
        "            return float(valor)\n",
        "    #Net assets table\n",
        "    net_assets = pd.DataFrame()\n",
        "    for ticker in tqdm(tickers):\n",
        "        url = f\"https://finance.yahoo.com/quote/{ticker}?p={ticker}\"\n",
        "        response = requests.get(url, headers=HEADERS)\n",
        "        try:\n",
        "            tables = pd.read_html(response.text)\n",
        "            for table in tables:\n",
        "                labels_to_remove = [\"Previous Close\", \"Open\", \"Bid\", \"Ask\", \"Day's Range\", \"52 Week Range\", \"Volume\",\"Avg. Volume\"]\n",
        "                table = table[~table.iloc[:, 0].isin(labels_to_remove)]\n",
        "                data_series = pd.Series(dict(zip(table.iloc[:, 0], table.iloc[:, 1])))\n",
        "                net_assets[ticker] = data_series\n",
        "        except ValueError:\n",
        "            print(f\"No hay tablas para {ticker}\")\n",
        "        time.sleep(0.5)\n",
        "    net_assets = net_assets.T\n",
        "    # Eliminar columnas\n",
        "    df = net_assets.drop(['NAV', 'PE Ratio (TTM)', 'Expense Ratio (net)'], axis=1)\n",
        "    # Corregir nombres de columnas\n",
        "    df.columns = corregir_nombres_columnas(df.columns)\n",
        "    # Convertir todas las entradas a strings, eliminar el '%' y reemplazar comas por puntos\n",
        "    df[['Yield', 'YTD_Daily_Total_Return']] = df[['Yield', 'YTD_Daily_Total_Return']].map(lambda x: str(x).replace('%', ''))\n",
        "    # Convertir las cadenas a números flotantes y dividir por 100 para tener los porcentajes en formato decimal\n",
        "    df[['Yield', 'YTD_Daily_Total_Return']] = df[['Yield', 'YTD_Daily_Total_Return']].map(lambda x: float(x) / 100.0)\n",
        "    # Convertir la columna Beta a float\n",
        "    df['Beta_5Y_Monthly'] = df['Beta_5Y_Monthly'].astype(float)\n",
        "    # Convertir Inception_Date en datetime\n",
        "    df['Inception_Date'] = pd.to_datetime(df['Inception_Date'], format='%Y-%m-%d')\n",
        "    # Reformatear columna Net_Assets\n",
        "    df['Net_Assets_Millions'] = df['Net_Assets'].apply(convertir_valor)\n",
        "    df = df.drop('Net_Assets', axis=1)\n",
        "    # Resetear índice\n",
        "    df = df.reset_index()\n",
        "    df = df.rename(columns={'index':'Ticker'})\n",
        "    # Retornar df\n",
        "    return(df)\n",
        "\n",
        "def portafolio_activos_etfs(tickers:list)->pd.DataFrame:\n",
        "    all_dataframes = []\n",
        "    for ticker in tqdm(tickers):\n",
        "        url = f\"https://finance.yahoo.com/quote/{ticker}/holdings?p={ticker}\"\n",
        "        response = requests.get(url, headers=HEADERS)\n",
        "        try:\n",
        "            tables = pd.read_html(response.text)\n",
        "            for table in tables:\n",
        "                table['Ticker'] = ticker  # Add the 'Ticker' column\n",
        "                all_dataframes.append(table)\n",
        "        except ValueError:\n",
        "            print(f\"No tables found for {ticker}\")\n",
        "        time.sleep(0.5)\n",
        "    # Concatenate all dataframes\n",
        "    df = pd.concat(all_dataframes, ignore_index=True)\n",
        "    # Corregir nombres de columnas\n",
        "    df.columns = corregir_nombres_columnas(df.columns)\n",
        "    df.rename(columns={\"_Assets\":\"Assets\"}, inplace=True)\n",
        "    # Convertir todas las entradas a strings, eliminar el '%' y reemplazar comas por puntos\n",
        "    df['Assets'] = df['Assets'].map(lambda x: str(x).replace('%', ''))\n",
        "    # Convertir las cadenas a números flotantes y dividir por 100 para tener los porcentajes en formato decimal\n",
        "    df['Assets'] = df['Assets'].map(lambda x: float(x) / 100.0)\n",
        "    # Retornar df\n",
        "    return(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Selección ETFs\n",
        "tickers = seleccion_etf(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmhqF1XRBXjT"
      },
      "outputs": [],
      "source": [
        "# Descargar y extraer todos los datos\n",
        "df_price_vol = convertir_a_largo(down_price_vol(tickers))\n",
        "df_sect_dist = web_scraping_sectors(tickers)\n",
        "df_net_activos = tabla_net_assets(tickers)\n",
        "df_portafolio_activos = portafolio_activos_etfs(tickers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtener el índice de referencia\n",
        "df_price_vol_temp = convertir_a_ancho(df_price_vol)\n",
        "sp500 = yf.download(tickers = '^GSPC', period='max')\n",
        "sp500 = sp500['Adj Close'].dropna().pct_change(1).dropna()\n",
        "sp500.index.name = 'Fecha'\n",
        "sp500 = sp500.reindex(df_price_vol_temp.index)\n",
        "# Se calcula la Beta y se asigna a la columna\n",
        "for ticker in tickers:\n",
        "    beta = df_price_vol_temp[('Precio', ticker)].cov(sp500) / sp500.var()\n",
        "    df_net_activos.loc[df_net_activos['Ticker'] == ticker, 'Beta_5Y_Monthly'] = beta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualizaciones Estadísticas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Descarga de datos desde Airtable ###\n",
        "# Dataframe sectores\n",
        "air = airtable.Airtable(base_id=base_id, table_name='tblWV2ERYBOrXozth', api_key=api_key)\n",
        "lista_de_diccionarios = air.get_all()\n",
        "lista_de_fields = [d['fields'] for d in lista_de_diccionarios]\n",
        "df_divsf_sect = pd.DataFrame(lista_de_fields)\n",
        "# Dataframe de activos netos\n",
        "air = airtable.Airtable(base_id=base_id, table_name='tblvbY1n5rzmFyBqZ', api_key=api_key)\n",
        "lista_de_diccionarios = air.get_all()\n",
        "lista_de_fields = [d['fields'] for d in lista_de_diccionarios]\n",
        "df_divsf_activos = pd.DataFrame(lista_de_fields)\n",
        "df_divsf_activos_reducido = df_divsf_activos[['Ticker', 'Yield', 'Beta_5Y_Monthly']]\n",
        "# Merge\n",
        "df_divsf_rend = pd.merge(df_divsf_sect, df_divsf_activos_reducido, on='Ticker', how='right')\n",
        "df_divsf_rend = df_divsf_rend.rename(columns={'Yield':'Rentabilidad', 'Beta_5Y_Monthly':'Riesgo'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shpoLlI7BhP4"
      },
      "outputs": [],
      "source": [
        "### Identificar el sector con la mayor inversión en promedio ###\n",
        "# Cálculo y selección\n",
        "sector_columns = df_divsf_rend.columns[2:-3]\n",
        "df_grafico_1 = df_divsf_rend[sector_columns].mean().sort_values(ascending=False)\n",
        "# Visualización\n",
        "plt.figure(figsize=(14,7))\n",
        "df_grafico_1.plot(kind='bar', color='skyblue')\n",
        "plt.title('Inversión Promedio en Cada Sector')\n",
        "plt.xlabel('Sectores')\n",
        "plt.ylabel('Inversión Promedio (Proporción)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Determinar el umbral para los ETFs más rentables (el cuartil superior) ###\n",
        "quantil_rentabilidad = df_divsf_rend['Rentabilidad'].quantile(0.75)\n",
        "etfs_mas_rentables = df_divsf_rend[df_divsf_rend['Rentabilidad'] >= quantil_rentabilidad]\n",
        "# Calcular\n",
        "df_grafico_2 = etfs_mas_rentables[sector_columns].mean().sort_values(ascending=False)\n",
        "# Visualizar\n",
        "plt.figure(figsize=(14,7))\n",
        "df_grafico_2.plot(kind='bar', color='green')\n",
        "plt.title('Inversión Promedio en Cada Sector para los ETFs más Rentables')\n",
        "plt.xlabel('Sectores')\n",
        "plt.ylabel('Inversión Promedio (Proporción)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Top rentabilidad-riesgo ETFs ###\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.scatterplot(data=df_divsf_activos, x=\"Beta_5Y_Monthly\", y=\"Yield\")\n",
        "plt.title(\"Relación entre Riesgo (Beta) y Rentabilidad (Yield)\")\n",
        "plt.xlabel(\"Beta 5Y Monthly\")\n",
        "plt.ylabel(\"Yield\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Descarga de datos desde Airtable ###\n",
        "air = airtable.Airtable(base_id=base_id, table_name='tblvxs74FGznyUCfL', api_key=api_key)\n",
        "lista_de_diccionarios = air.get_all()\n",
        "lista_de_fields = [d['fields'] for d in lista_de_diccionarios]\n",
        "df_activos_repiten = pd.DataFrame(lista_de_fields)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Portafolio de activos recurrentes ###\n",
        "# Repeticiones\n",
        "symbol_repetitions = df_activos_repiten['Symbol'].value_counts().reset_index()\n",
        "symbol_repetitions.columns = ['Symbol', 'Repetitions']\n",
        "# Filtrar\n",
        "symbol_repetitions = symbol_repetitions[symbol_repetitions['Repetitions'] > 1]\n",
        "# Mediana\n",
        "median_assets_by_symbol = df_activos_repiten[df_activos_repiten['Symbol'].isin(symbol_repetitions['Symbol'])]\n",
        "median_assets_by_symbol = median_assets_by_symbol.groupby('Symbol')['Assets'].median().reset_index()\n",
        "median_assets_by_symbol.columns = ['Symbol', 'Median_Assets']\n",
        "# Obtener el nombre\n",
        "name_by_symbol = df_activos_repiten.groupby('Symbol')['Name'].first().reset_index()\n",
        "# Ordenar resultado\n",
        "median_assets_by_symbol = median_assets_by_symbol.sort_values(by='Median_Assets', ascending=False)\n",
        "# Visualizar\n",
        "fig = px.bar(median_assets_by_symbol, x='Symbol', y='Median_Assets', color=symbol_repetitions['Repetitions'],\n",
        "             color_continuous_scale=px.colors.sequential.Viridis,\n",
        "             labels={'Symbol': 'Symbol', 'Median_Assets': 'Median Assets', 'color': 'Repeticiones'},\n",
        "             title='Mediana de Assets por Symbol con Repeticiones (Excluyendo Repeticiones Únicas)')\n",
        "fig.update_xaxes(tickangle=45)\n",
        "fig.update_traces(text=name_by_symbol['Name'], textposition='outside')\n",
        "fig.update_layout(xaxis_title='Symbol', yaxis_title='Median Assets')\n",
        "fig.update_layout(coloraxis_showscale=False)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Descarga de datos ###\n",
        "air = airtable.Airtable(base_id=base_id, table_name='tblkKLqcgl5dDo6uI', api_key=api_key)\n",
        "lista_de_diccionarios = air.get_all()\n",
        "lista_de_fields = [d['fields'] for d in lista_de_diccionarios]\n",
        "df_price_vol_temp = convertir_a_ancho(pd.DataFrame(lista_de_fields))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Suma de los cambios porcentuales diarios del Top 25 ###\n",
        "# Sumamos todas las variaciones porcentuales para obtener la variación total\n",
        "total_pct_change = pd.DataFrame(df_price_vol_temp['Precio'].sum(axis=1))\n",
        "# Visualizar\n",
        "sns.histplot(total_pct_change, bins=100, kde=False, color=\"green\")\n",
        "# Distribución\n",
        "params = stats.norm.fit(total_pct_change)\n",
        "x = np.linspace(total_pct_change.min(), total_pct_change.max(), 100)\n",
        "y = stats.norm.pdf(x, *params)\n",
        "plt.plot(x, y, color=\"red\") \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_capital = (df_price_vol_temp['Precio'] + 1).cumprod().sum(axis=1)\n",
        "df_capital.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Para continuar con el trabajo ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "annual_report = {\n",
        "    \"operatingCashflow\": \"10435000000\",  # Efectivo de operaciones\n",
        "    \"capitalExpenditures\": \"1346000000\",  # Gastos de capital\n",
        "    \"netIncome\": \"1639000000\",  # Ingreso neto\n",
        "    # ...Incluir el resto de los campos...\n",
        "}\n",
        "\n",
        "# Convertir todas las cadenas a enteros o floats según sea necesario\n",
        "for key in annual_report:\n",
        "    annual_report[key] = int(annual_report[key]) if annual_report[key] is not None else 0\n",
        "\n",
        "# Free Cash Flow (FCF)\n",
        "def calculate_fcf(operating_cash_flow, capital_expenditures):\n",
        "    return operating_cash_flow - capital_expenditures\n",
        "\n",
        "# Free Cash Flow Yield\n",
        "def calculate_fcf_yield(free_cash_flow, market_cap):\n",
        "    return free_cash_flow / market_cap\n",
        "\n",
        "# Margen de FCF\n",
        "def calculate_fcf_margin(free_cash_flow, total_revenue):\n",
        "    return free_cash_flow / total_revenue\n",
        "\n",
        "# Crecimiento del FCF YoY no puede calcularse solo con un año de datos\n",
        "# Necesitaría al menos dos años de datos para calcular esto.\n",
        "\n",
        "# Ratios de rentabilidad (como ROE, ROA, ROI)\n",
        "def calculate_roi(net_income, total_investment):\n",
        "    return net_income / total_investment\n",
        "\n",
        "def calculate_roe(net_income, shareholder_equity):\n",
        "    return net_income / shareholder_equity\n",
        "\n",
        "def calculate_roa(net_income, total_assets):\n",
        "    return net_income / total_assets\n",
        "\n",
        "# Ratios de valoración (como P/E, P/FCF)\n",
        "# Para estos cálculos necesitaríamos el precio de las acciones (P) y el número de acciones en circulación para calcular el P/E y P/FCF\n",
        "\n",
        "# El Análisis de deuda requeriría datos sobre la deuda total y los intereses pagados\n",
        "\n",
        "# Ratios de liquidez (como Current Ratio, Quick Ratio)\n",
        "# Necesitaríamos conocer el total de activos corrientes y pasivos corrientes para calcular estos\n",
        "\n",
        "# Efficiency Ratios (como rotación de inventario, DSO, y DPO)\n",
        "# También se necesitarían datos adicionales, como ingresos por ventas, costo de bienes vendidos e inventario inicial y final\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "qbZkKpyC9AEK",
        "Fe2VYO2XiTyD",
        "hmhqF1XRBXjT",
        "t5ckS1EcBdJw",
        "SLyPfgjRBiLZ"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
